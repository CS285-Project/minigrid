name: llama
channels:
  - defaults
dependencies:
  - _libgcc_mutex=0.1=main
  - _openmp_mutex=5.1=1_gnu
  - ca-certificates=2023.08.22=h06a4308_0
  - ld_impl_linux-64=2.38=h1181459_1
  - libffi=3.3=he6710b0_2
  - libgcc-ng=11.2.0=h1234567_1
  - libgomp=11.2.0=h1234567_1
  - libstdcxx-ng=11.2.0=h1234567_1
  - ncurses=6.4=h6a678d5_0
  - openssl=1.1.1w=h7f8727e_0
  - pip=23.3=py39h06a4308_0
  - python=3.9.0=hdb3f193_2
  - readline=8.2=h5eee18b_0
  - setuptools=68.0.0=py39h06a4308_0
  - sqlite=3.41.2=h5eee18b_0
  - tk=8.6.12=h1ccaba5_0
  - tzdata=2023c=h04d1e81_0
  - wheel=0.41.2=py39h06a4308_0
  - xz=5.4.2=h5eee18b_0
  - zlib=1.2.13=h5eee18b_0
  - pip:
    - certifi==2023.7.22
    - charset-normalizer==3.3.2
    - cmake==3.27.7
    - fairscale==0.4.13
    - filelock==3.13.1
    - fire==0.5.0
    - idna==3.4
    - jinja2==3.1.2
    - lit==17.0.4
    - markupsafe==2.1.3
    - mpmath==1.3.0
    - networkx==3.2.1
    - numpy==1.26.1
    - nvidia-cublas-cu11==11.10.3.66
    - nvidia-cuda-cupti-cu11==11.7.101
    - nvidia-cuda-nvrtc-cu11==11.7.99
    - nvidia-cuda-runtime-cu11==11.7.99
    - nvidia-cudnn-cu11==8.5.0.96
    - nvidia-cufft-cu11==10.9.0.58
    - nvidia-curand-cu11==10.2.10.91
    - nvidia-cusolver-cu11==11.4.0.1
    - nvidia-cusparse-cu11==11.7.4.91
    - nvidia-nccl-cu11==2.14.3
    - nvidia-nvtx-cu11==11.7.91
    - pillow==10.1.0
    - requests==2.31.0
    - sentencepiece==0.1.99
    - six==1.16.0
    - sympy==1.12
    - termcolor==2.3.0
    - torch==2.0.1
    - torchaudio==2.0.2
    - torchvision==0.15.2
    - triton==2.0.0
    - typing-extensions==4.8.0
    - urllib3==2.0.7
prefix: /data1/lzengaf/anaconda3/envs/llama
